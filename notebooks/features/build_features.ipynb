{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile as wv\n",
    "from scipy import signal\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import welch\n",
    "from scipy import stats\n",
    "from detect_peaks import detect_peaks\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data/processed/submission.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_freq = 22050 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(raw_signal):\n",
    "\n",
    "    # Rectification \n",
    "    rectified_signal = np.abs(raw_signal)\n",
    "\n",
    "    # Low-pass filtering -> envelope\n",
    "    sample_freq = 22050 # Hz\n",
    "    cutoff_freq = 5     # Hz\n",
    "    norm_cutoff_freq = cutoff_freq / (sample_freq / 2.0)\n",
    "    b, a = signal.butter(2, norm_cutoff_freq, 'low')\n",
    "    envelope = signal.filtfilt(b, a, rectified_signal, axis=0)\n",
    "\n",
    "    return envelope, rectified_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(raw_signal):\n",
    "    n5 = np.nanpercentile(raw_signal, 5)\n",
    "    n25 = np.nanpercentile(raw_signal, 25)\n",
    "    n75 = np.nanpercentile(raw_signal, 75)\n",
    "    n95 = np.nanpercentile(raw_signal, 95)\n",
    "    median = np.nanpercentile(raw_signal, 50)\n",
    "    mean = np.nanmean(raw_signal)\n",
    "    std = np.nanstd(raw_signal)\n",
    "    var = np.nanvar(raw_signal)\n",
    "    rms = np.nanmean(np.sqrt(raw_signal**2))\n",
    "    maxv =np.max(raw_signal)\n",
    "    minv = np.min(raw_signal)\n",
    "    skew = stats.skew(raw_signal)\n",
    "    kurtosis = stats.kurtosis(raw_signal)\n",
    "    absmean = np.abs(raw_signal).mean()\n",
    "    absstd = np.abs(raw_signal).std()\n",
    "    \n",
    "    \n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms, maxv, minv, skew, kurtosis, absmean, absstd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_signal_features(raw_signal):\n",
    "    relamp = np.max(raw_signal) / np.abs(np.min(raw_signal))\n",
    "    amp = np.max(raw_signal) - np.abs(np.min(raw_signal))\n",
    "    ssum = np.sum(raw_signal)\n",
    "    diffmean = np.mean(np.diff(raw_signal))\n",
    "    \n",
    "    return [relamp, amp, ssum, diffmean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[len(result)//2:]\n",
    "\n",
    "def get_autocorr_values(y_values, f_s):\n",
    "    N = len(y_values)\n",
    "    T = 1/f_s\n",
    "    autocorr_values = autocorr(y_values)\n",
    "    x_values = np.array([T * jj for jj in range(0, N)])\n",
    "    return x_values, autocorr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft_values(y_values, f_s):\n",
    "    T = 1/f_s\n",
    "    N = len(y_values)\n",
    "    f_values = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    fft_values_ = fft(y_values)\n",
    "    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])\n",
    "    return f_values, fft_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psd_values(y_values, f_s):\n",
    "    f_values, psd_values = welch(y_values, fs=f_s)\n",
    "    return f_values, psd_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_n_peaks(x,y,no_peaks=5):\n",
    "    x_, y_ = list(x), list(y)\n",
    "    if len(x_) > no_peaks:\n",
    "        return x_[:no_peaks], y_[:no_peaks]\n",
    "    else:\n",
    "        missing_no_peaks = no_peaks-len(x_)\n",
    "        return x_ + [0]*missing_no_peaks, y_ + [0]*missing_no_peaks\n",
    "    \n",
    "def get_peaks(x_values, y_values, mph):\n",
    "    indices_peaks = detect_peaks(y_values, mph=mph)\n",
    "    peaks_x, peaks_y = get_first_n_peaks(x_values[indices_peaks], y_values[indices_peaks])\n",
    "    return peaks_x + peaks_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_crossings(list_values):\n",
    "    zero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
    "    no_zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "    no_mean_crossings = len(mean_crossing_indices)\n",
    "    return [no_zero_crossings, no_mean_crossings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(list_values):\n",
    "    counter_values = Counter(list_values).most_common()\n",
    "    probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "    entropy = stats.entropy(probabilities)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(raw_signal, f_s):\n",
    "    \n",
    "    envelope, rectified_signal = preprocessing(raw_signal)\n",
    "    \n",
    "    threshold = 0.0115 * (2 ** 16) # to compute duration and envelope slope sign\n",
    "    above_thres = envelope >= threshold  # samples to consider in computation\n",
    "    \n",
    "    max_pos = np.argmax(envelope)\n",
    "    envelope_slope_sign = np.sign(np.diff(envelope, append=0)) * above_thres    \n",
    "    duration_signal = np.ones(envelope.shape) * above_thres\n",
    "\n",
    "    # features\n",
    "    features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    features += calculate_statistics(raw_signal)\n",
    "    feature_names += ['rsig_' + i for i in ['n5', 'n25', 'n75', 'n95', 'median', 'mean', 'std', 'var', 'rms', 'maxv', 'minv', 'skew', 'kurtosis', 'absmean', 'absstd']]\n",
    "    \n",
    "    features += calculate_signal_features(raw_signal)\n",
    "    feature_names += ['rsig_' + i for i in ['relamp', 'amp', 'ssum', 'diffmean']]\n",
    "    \n",
    "    features += calculate_crossings(raw_signal)\n",
    "    feature_names += ['rsig_' + i for i in ['no_zero_crossings', 'no_mean_crossings']]\n",
    "    \n",
    "    features += calculate_statistics(get_fft_values(raw_signal, f_s)[1])\n",
    "    feature_names += ['rsig_fft_' + i for i in ['n5', 'n25', 'n75', 'n95', 'median', 'mean', 'std', 'var', 'rms', 'maxv', 'minv', 'skew', 'kurtosis', 'absmean', 'absstd']]\n",
    "    \n",
    "    features += calculate_statistics(get_psd_values(raw_signal, f_s)[1])\n",
    "    feature_names += ['rsig_psd_' + i for i in ['n5', 'n25', 'n75', 'n95', 'median', 'mean', 'std', 'var', 'rms', 'maxv', 'minv', 'skew', 'kurtosis', 'absmean', 'absstd']]\n",
    "\n",
    "    \n",
    "    # peaks\n",
    "    percentile = 5\n",
    "    denominator = 10\n",
    "    \n",
    "            \n",
    "    signal_min = np.nanpercentile(raw_signal, percentile)\n",
    "    signal_max = np.nanpercentile(raw_signal, 100-percentile)\n",
    "    mph = signal_min + (signal_max - signal_min)/denominator\n",
    "\n",
    "    peaks_detected = get_peaks(*get_psd_values(raw_signal, f_s), mph)\n",
    "    features += peaks_detected\n",
    "    feature_names += ['peak_psd_' + str(i) for i in range(len(peaks_detected))]\n",
    "    \n",
    "    peaks_detected = get_peaks(*get_fft_values(raw_signal, f_s), mph)\n",
    "    features += peaks_detected\n",
    "    feature_names += ['peak_fft_' + str(i) for i in range(len(peaks_detected))]\n",
    "    \n",
    "    \n",
    "    peaks_detected = get_peaks(*get_autocorr_values(raw_signal, f_s), mph)\n",
    "    features += peaks_detected\n",
    "    feature_names += ['peak_corr_' + str(i) for i in range(len(peaks_detected))]\n",
    "    \n",
    "    # wavelet\n",
    "    wave_families = ['haar', 'bior1.5', 'coif1', 'db1', 'sym2']\n",
    "    for waveletname in wave_families:\n",
    "        list_coeff = pywt.wavedec(raw_signal, waveletname)\n",
    "        for n_coef, coeff in enumerate(list_coeff):\n",
    "            features += [calculate_entropy(coeff)]\n",
    "            feature_names += ['entro_' + waveletname + '_coeff_' + str(n_coef)]\n",
    "            \n",
    "            features += calculate_crossings(coeff)\n",
    "            feature_names += [waveletname + '_' + i + '_coeff_' + str(n_coef) for i in ['no_zero_crossings', 'no_mean_crossings']]\n",
    "            \n",
    "            features += calculate_statistics(coeff)\n",
    "            feature_names += [waveletname + '_' + i + '_coeff_' + str(n_coef) for i in ['n5', 'n25', 'n75', 'n95', 'median', 'mean', 'std', 'var', 'rms', 'maxv', 'minv', 'skew', 'kurtosis', 'absmean', 'absstd']]\n",
    "\n",
    "\n",
    "    \n",
    "    duration = np.sum(duration_signal)\n",
    "    zero_crossing = np.count_nonzero(np.abs(np.diff(envelope_slope_sign)))\n",
    "    amplitude = max(rectified_signal)\n",
    "    ratio = np.trapz(envelope[:max_pos], axis=0) / np.trapz(envelope, axis=0)\n",
    "\n",
    "    features += [duration, zero_crossing, float(amplitude), float(ratio)]\n",
    "    feature_names += ['duration', 'zero_crossing', 'amplitude', 'ratio']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return features, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7b191cff47474fa20e0b1eec09ee2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inicialize X zeros array \n",
    "X_features = [] #np.zeros([X.shape[0], 85])\n",
    "feature_names = []\n",
    "for idx in trange(X.shape[0]):\n",
    "    #X_features[idx, :] = get_features(X[idx, :], sample_freq)\n",
    "    if idx == 0:\n",
    "        features, feature_names_ = get_features(X[idx, :], sample_freq)\n",
    "        X_features.append(features)\n",
    "        feature_names = feature_names_\n",
    "    else:\n",
    "        X_features.append(get_features(X[idx, :], sample_freq)[0])\n",
    "        pass\n",
    "    pass\n",
    "X_features = np.array(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/features/submission_002.npy',X_features)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save('data/features/X_features_names_002.npy',feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = np.load('data/features/X_features_002.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.load('data/features/X_features_names_002.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1269]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i, name in enumerate(feature_names) if name == 'duration']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Signal (env)",
   "language": "python",
   "name": "signalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
