{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD DISCRETE WAVELET FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile as wv\n",
    "from scipy import signal\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import welch\n",
    "from scipy import stats\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pywt\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data/processed/X.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_freq = 22050 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(raw_signal):\n",
    "\n",
    "    # Rectification \n",
    "    rectified_signal = np.abs(raw_signal)\n",
    "\n",
    "    # Low-pass filtering -> envelope\n",
    "    sample_freq = 22050 # Hz\n",
    "    cutoff_freq = 5     # Hz\n",
    "    norm_cutoff_freq = cutoff_freq / (sample_freq / 2.0)\n",
    "    b, a = signal.butter(2, norm_cutoff_freq, 'low')\n",
    "    envelope = signal.filtfilt(b, a, rectified_signal, axis=0)\n",
    "\n",
    "    return envelope, rectified_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(raw_signal):\n",
    "    n5 = np.nanpercentile(raw_signal, 5)\n",
    "    n25 = np.nanpercentile(raw_signal, 25)\n",
    "    n75 = np.nanpercentile(raw_signal, 75)\n",
    "    n95 = np.nanpercentile(raw_signal, 95)\n",
    "    median = np.nanpercentile(raw_signal, 50)\n",
    "    mean = np.nanmean(raw_signal)\n",
    "    std = np.nanstd(raw_signal)\n",
    "    var = np.nanvar(raw_signal)\n",
    "    rms = np.nanmean(np.sqrt(raw_signal**2))\n",
    "    maxv =np.max(raw_signal)\n",
    "    minv = np.min(raw_signal)\n",
    "    skew = stats.skew(raw_signal)\n",
    "    kurtosis = stats.kurtosis(raw_signal)\n",
    "    absmean = np.abs(raw_signal).mean()\n",
    "    absstd = np.abs(raw_signal).std()\n",
    "    \n",
    "    \n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms, maxv, minv, skew, kurtosis, absmean, absstd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_signal_features(raw_signal):\n",
    "    relamp = np.max(raw_signal) / np.abs(np.min(raw_signal))\n",
    "    amp = np.max(raw_signal) - np.abs(np.min(raw_signal))\n",
    "    ssum = np.sum(raw_signal)\n",
    "    diffmean = np.mean(np.diff(raw_signal))\n",
    "    \n",
    "    return [relamp, amp, ssum, diffmean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[len(result)//2:]\n",
    "\n",
    "def get_autocorr_values(y_values, f_s):\n",
    "    N = len(y_values)\n",
    "    T = 1/f_s\n",
    "    autocorr_values = autocorr(y_values)\n",
    "    x_values = np.array([T * jj for jj in range(0, N)])\n",
    "    return x_values, autocorr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft_values(y_values, f_s):\n",
    "    T = 1/f_s\n",
    "    N = len(y_values)\n",
    "    f_values = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    fft_values_ = fft(y_values)\n",
    "    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])\n",
    "    return f_values, fft_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psd_values(y_values, f_s):\n",
    "    f_values, psd_values = welch(y_values, fs=f_s)\n",
    "    return f_values, psd_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_crossings(list_values):\n",
    "    zero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
    "    no_zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "    no_mean_crossings = len(mean_crossing_indices)\n",
    "    return [no_zero_crossings, no_mean_crossings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(list_values):\n",
    "    counter_values = Counter(list_values).most_common()\n",
    "    probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "    entropy = stats.entropy(probabilities)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wavelet_features(raw_signal, f_s):\n",
    "    \n",
    "    #envelope, rectified_signal = preprocessing(raw_signal)\n",
    "    \n",
    "    #threshold = 0.0115 * (2 ** 16) # to compute duration and envelope slope sign\n",
    "    #above_thres = envelope >= threshold  # samples to consider in computation\n",
    "    \n",
    "    #max_pos = np.argmax(envelope)\n",
    "    #envelope_slope_sign = np.sign(np.diff(envelope, append=0)) * above_thres    \n",
    "    #duration_signal = np.ones(envelope.shape) * above_thres\n",
    "\n",
    "    # features\n",
    "    features = []\n",
    "    feature_names = []\n",
    "       \n",
    "    \n",
    "    # wavelet\n",
    "    wave_families = pywt.wavelist(kind='discrete')\n",
    "        \n",
    "    for waveletname in wave_families:\n",
    "        list_coeff = pywt.wavedec(raw_signal, waveletname)\n",
    "        for n_coef, coeff in enumerate(list_coeff):\n",
    "            features += [calculate_entropy(coeff)]\n",
    "            feature_names += ['entro_' + waveletname + '_coeff_' + str(n_coef)]\n",
    "            \n",
    "            features += calculate_crossings(coeff)\n",
    "            feature_names += [waveletname + '_' + i + '_coeff_' + str(n_coef) for i in ['no_zero_crossings', 'no_mean_crossings']]\n",
    "            \n",
    "            features += calculate_statistics(coeff)\n",
    "            feature_names += [waveletname + '_' + i + '_coeff_' + str(n_coef) for i in ['n5', 'n25', 'n75', 'n95', 'median', 'mean', 'std', 'var', 'rms', 'maxv', 'minv', 'skew', 'kurtosis', 'absmean', 'absstd']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return features, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60d5757bde842eda54c78b4825ed4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1532), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inicialize X zeros array \n",
    "X_features = [] \n",
    "feature_names = []\n",
    "for idx in trange(X.shape[0]):\n",
    "    #X_features[idx, :] = get_features(X[idx, :], sample_freq)\n",
    "    if idx == 0:\n",
    "        features, feature_names_ = get_wavelet_features(X[idx, :], sample_freq)\n",
    "        X_features.append(features)\n",
    "        feature_names = feature_names_\n",
    "    else:\n",
    "        X_features.append(get_wavelet_features(X[idx, :], sample_freq)[0])\n",
    "        pass\n",
    "    pass\n",
    "X_features = np.array(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1532, 19746)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/features/X_wavelet_discrete_features.npy',X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/features/X_wavelet_discrete_names.npy',feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Signal (env)",
   "language": "python",
   "name": "signalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
