{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD CHROMA CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = 'data/processed/submission.npy'\n",
    "OUTPUT_PATH = 'data/features/submission_tonnetz.npy'\n",
    "SR = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave2tonnetz(wave, sr, normalize, max_pad_len, padding_mode):\n",
    "\n",
    "    #wave, sr = librosa.load(wav_file, mono=True)\n",
    "    \n",
    "    if 0 < len(wave): # workaround: 0 length causes error\n",
    "        wave, _ = librosa.effects.trim(wave) # trim, top_db=default(60)\n",
    "\n",
    "    if normalize:\n",
    "        wave = librosa.util.normalize(wave) # normalizing data before mfcc\n",
    "\n",
    "    # making melspect from signal\n",
    "    S = librosa.feature.tonnetz(y=wave, sr=sr)\n",
    "\n",
    "    if max_pad_len:\n",
    "        if S.shape[1] > max_pad_len:\n",
    "            S = S[:,:max_pad_len]\n",
    "        else:\n",
    "            pad_width = max_pad_len - S.shape[1]\n",
    "            S = np.pad(S, pad_width=((0, 0), (0, pad_width)), mode=padding_mode)\n",
    "\n",
    "   \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tonnetz(input_path, output_path, sr,  max_pad_len=None, normalize=True, padding_mode='constant'):\n",
    "    \n",
    "    # Load wave files\n",
    "    wavfiles = np.load(input_path)\n",
    "    \n",
    "    # Init Mel vectors\n",
    "    X_tonnetz = []\n",
    "    \n",
    "    for idx in trange(wavfiles.shape[0]):\n",
    "        X_tonnetz.append(wave2tonnetz(wavfiles[idx, :], sr, max_pad_len=max_pad_len, \n",
    "                             normalize=normalize, padding_mode=padding_mode))\n",
    "        pass\n",
    "    \n",
    "    X_tonnetz = np.array(X_tonnetz)\n",
    "    \n",
    "    # Saving Mels \n",
    "    np.save(output_path, X_tonnetz)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acedadae8551448fbffb0f055120e0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen_tonnetz(INPUT_PATH, OUTPUT_PATH, SR, normalize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Signal (env)",
   "language": "python",
   "name": "signalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
