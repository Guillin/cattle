{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = 'data/features/'\n",
    "SEED = 47\n",
    "NITER = 100\n",
    "CV = 3\n",
    "SCORE = 'balanced_accuracy'\n",
    "handlingnull = False\n",
    "NJOBS = 7\n",
    "USEGPU = True\n",
    "NCLASS = 3 # number class to predict (if bivar set 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.load(DATAPATH+'X_features_002.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load(DATAPATH+'y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== General Parameters ======= #\n",
    "\n",
    "# Select the type of model to run at each iteration. gbtree or gblinear.\n",
    "booster = 'gbtree'\n",
    "\n",
    "\n",
    "# ======== Booster Parameters ======== # \n",
    "\n",
    "# Analogous to learning rate in GBM. \n",
    "# Typical final values to be used: 0.01-0.2\n",
    "eta = [0.01] \n",
    "\n",
    "\n",
    "# Control the balance of positive and negative weights, useful for unbalanced classes. \n",
    "# A typical value to consider: sum(negative instances) / sum(positive instances)scale_pos_weight = 1\n",
    "scale_pos_weight = [5,1,2]\n",
    "\n",
    "\n",
    "# Learning Task Parameters\n",
    "\n",
    "# This defines the loss function to be minimized. \n",
    "# - binary:logistic –logistic regression for binary classification, returns predicted probability (not class)\n",
    "# - multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities)\n",
    "#   you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "# - multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "objective  = 'multi:softprob'\n",
    "\n",
    "\n",
    "# The metric to be used for validation data.\n",
    "# - rmse – root mean square error\n",
    "# - mae – mean absolute error\n",
    "# - logloss – negative log-likelihood\n",
    "# - error – Binary classification error rate (0.5 threshold)\n",
    "# - merror – Multiclass classification error rate\n",
    "# - mlogloss – Multiclass logloss\n",
    "# - auc: Area under the curve\n",
    "eval_metric = 'mlogloss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = np.load('output/hyperparameters/gseach_xgboost_classifier_bestparams_d2019-11-09.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params['seed'] = SEED\n",
    "xgb_params['booster'] = booster\n",
    "xgb_params['objective'] = objective\n",
    "xgb_params['eval_metric'] = eval_metric\n",
    "xgb_params['num_threads'] = NJOBS\n",
    "xgb_params['num_class'] = NCLASS\n",
    "xgb_params['verbose'] = 0\n",
    "xgb_params['scale_pos_weight'] = scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params['n_estimators'] = 402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USEGPU:\n",
    "    xgb_params['tree_method'] = 'gpu_hist'\n",
    "    xgb_params['gpu_id'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.72,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 3,\n",
       " 'reg_alpha': 0.001,\n",
       " 'reg_lambda': 0.9,\n",
       " 'subsample': 0.85,\n",
       " 'seed': 47,\n",
       " 'booster': 'gbtree',\n",
       " 'objective': 'multi:softprob',\n",
       " 'eval_metric': 'mlogloss',\n",
       " 'num_threads': 7,\n",
       " 'num_class': 3,\n",
       " 'verbose': 0,\n",
       " 'scale_pos_weight': [5, 1, 2],\n",
       " 'n_estimators': 402,\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'gpu_id': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a DMatrix and handling Null values\n",
    "if handlingnull:\n",
    "    #train_features[np.isnan(train_features)] = -9999\n",
    "    xgtrain = xgb.DMatrix(train_features, train_labels, missing=-9999)\n",
    "else:\n",
    "    xgtrain = xgb.DMatrix(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(xgb_params, xgtrain, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('models/xgb_002.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xgboost GPU(env)",
   "language": "python",
   "name": "xgbgpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
